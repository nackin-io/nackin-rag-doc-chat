# ğŸ§  RAG Document Intelligence Chat

> AI-powered document Q&A â€” upload PDFs, ask questions, get cited answers using retrieval-augmented generation.

[![Live Demo](https://img.shields.io/badge/demo-live-brightgreen?style=flat-square)](https://nackin-rag-doc-chat.vercel.app)
[![Next.js](https://img.shields.io/badge/Next.js_15-black?style=flat-square&logo=next.js)](https://nextjs.org)
[![TypeScript](https://img.shields.io/badge/TypeScript-3178C6?style=flat-square&logo=typescript&logoColor=white)](https://www.typescriptlang.org)
[![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=flat-square&logo=openai&logoColor=white)](https://openai.com)
[![Supabase](https://img.shields.io/badge/Supabase-3FCF8E?style=flat-square&logo=supabase&logoColor=white)](https://supabase.com)
[![Vercel](https://img.shields.io/badge/Vercel-000?style=flat-square&logo=vercel)](https://vercel.com)

> âš ï¸ **Demo Version** â€” Based on a production system built for a real client. Sensitive data and proprietary business logic have been removed.

---

![App Screenshot](./public/screenshot.png)

---

## âœ¨ Features

- ğŸ“„ **PDF Upload** â€” Drag & drop with progress indicator, validation, and Supabase Storage
- ğŸ” **RAG Pipeline** â€” Parse â†’ Chunk â†’ Embed â†’ Store â†’ Retrieve with pgvector similarity search
- ğŸ’¬ **Streaming Chat** â€” Real-time AI responses with typewriter effect and conversation history
- ğŸ“ **Source Citations** â€” Expandable citation chips showing matched document chunks with similarity scores
- ğŸŒ— **Dark Mode** â€” System-aware theme toggle persisted in localStorage
- ğŸ“± **Responsive** â€” Mobile-first design with collapsible sidebar
- ğŸ—‚ï¸ **Multi-Document** â€” Chat with a specific document or across all uploads

---

## ğŸ— Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Browser     â”‚â”€â”€â”€â”€â–¶â”‚  Next.js API â”‚â”€â”€â”€â”€â–¶â”‚  OpenAI API      â”‚
â”‚  (React UI)   â”‚     â”‚   Routes     â”‚     â”‚  GPT-4o / embed  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   Supabase    â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚pgvector â”‚  â”‚
                    â”‚  â”‚ chunks  â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
                    â”‚  â”‚ Storage â”‚  â”‚
                    â”‚  â”‚  PDFs   â”‚  â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**How it works:**

1. **Upload** â€” PDF is uploaded to Supabase Storage and a document record is created
2. **Process** â€” `pdf-parse` extracts text; a recursive character splitter creates overlapping chunks (1000 chars, 200 overlap)
3. **Embed** â€” Each chunk is embedded via OpenAI `text-embedding-3-small` (1536 dimensions)
4. **Store** â€” Chunks + embeddings stored in Supabase with pgvector
5. **Query** â€” User message is embedded; pgvector finds top 5 similar chunks via cosine distance
6. **Answer** â€” GPT-4o generates a streaming answer grounded in retrieved context with source citations

---

## ğŸ›  Tech Stack

| Layer | Technology |
|---|---|
| Framework | Next.js 15 (App Router) |
| Language | TypeScript |
| Styling | Tailwind CSS + shadcn/ui |
| AI | OpenAI GPT-4o + text-embedding-3-small |
| Database | Supabase (PostgreSQL + pgvector) |
| Storage | Supabase Storage |
| PDF Parsing | pdf-parse |
| Theming | next-themes |
| Deployment | Vercel |

---

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- [Supabase](https://supabase.com) project (free tier works)
- [OpenAI API key](https://platform.openai.com/api-keys)

### 1. Clone & Install

```bash
git clone https://github.com/nackin-io/nackin-rag-doc-chat.git
cd nackin-rag-doc-chat
npm install
```

### 2. Environment Variables

```bash
cp .env.local.example .env.local
```

| Variable | Description |
|---|---|
| `OPENAI_API_KEY` | OpenAI API key for embeddings & chat |
| `NEXT_PUBLIC_SUPABASE_URL` | Your Supabase project URL |
| `NEXT_PUBLIC_SUPABASE_ANON_KEY` | Supabase anonymous/public key |
| `SUPABASE_SERVICE_ROLE_KEY` | Supabase service role key (server-side only) |

### 3. Supabase Setup

Run this SQL in your Supabase SQL Editor:

```sql
create extension if not exists vector;

create table documents (
  id uuid primary key default gen_random_uuid(),
  name text not null,
  size integer,
  status text default 'processing',
  created_at timestamptz default now()
);

create table document_chunks (
  id uuid primary key default gen_random_uuid(),
  document_id uuid references documents(id) on delete cascade,
  content text not null,
  embedding vector(1536),
  chunk_index integer,
  created_at timestamptz default now()
);

create or replace function match_chunks(
  query_embedding vector(1536),
  match_threshold float default 0.7,
  match_count int default 5,
  filter_doc_id uuid default null
)
returns table (id uuid, document_id uuid, content text, similarity float)
language sql stable as $$
  select id, document_id, content,
    1 - (embedding <=> query_embedding) as similarity
  from document_chunks
  where
    (filter_doc_id is null or document_id = filter_doc_id)
    and 1 - (embedding <=> query_embedding) > match_threshold
  order by embedding <=> query_embedding limit match_count;
$$;

alter table documents enable row level security;
alter table document_chunks enable row level security;
create policy "Allow all" on documents for all using (true);
create policy "Allow all" on document_chunks for all using (true);
```

Create a **Storage bucket** named `pdfs` (Storage â†’ New Bucket â†’ public: off).

### 4. Run

```bash
npm run dev
```

Open [http://localhost:3000](http://localhost:3000)

---

## ğŸ“ Project Structure

```
app/
â”œâ”€â”€ layout.tsx
â”œâ”€â”€ page.tsx
â””â”€â”€ api/
    â”œâ”€â”€ upload/route.ts
    â”œâ”€â”€ chat/route.ts
    â”œâ”€â”€ documents/route.ts
    â””â”€â”€ documents/[id]/route.ts
components/
â”œâ”€â”€ chat/
â”œâ”€â”€ upload/
â”œâ”€â”€ documents/
â””â”€â”€ ui/
lib/
â”œâ”€â”€ supabase.ts
â”œâ”€â”€ openai.ts
â”œâ”€â”€ pdf-processor.ts
â””â”€â”€ text-splitter.ts
types/
â””â”€â”€ index.ts
```

---

## ğŸ“„ License

MIT

---

> Built by [**Nackin**](https://nackin.io) â€” AI Engineering & Full-Stack Development Studio
